好的，下面是基于你 **CodeRAG Lab** 项目的12周计划，分解为每周的具体开发任务。这个计划将帮助你在3个月内逐步完成一个可落地的项目，能让你在实习面试时展示出实际可用的技术能力。

------

## **12 周学习实践计划**

### **Week 1：工程底座搭建 + 项目骨架**

**任务目标**：搭建项目基本框架，确保项目结构清晰且能够运行。

- **环境准备**：
  - 安装 Python 3.10+
  - 安装 Poetry（依赖管理）
  - 安装 Docker Desktop（用于启动 Qdrant）
  - 安装 Git Bash（可选，用于运行 `make` 等命令）
- **项目初始化**：
  - 创建项目文件夹及 Git 仓库
  - 配置 `pyproject.toml` 和 `.env.example`
  - 初始化项目文件结构（包括 `src/`, `data/` 等）
  - 配置 Docker Compose 以启动 Qdrant
  - 配置基本的日志模块、错误处理模块和配置文件
- **FastAPI 服务骨架搭建**：
  - 创建 `/health` 和 `/chat` API 接口（返回 mock 数据）
  - 配置好 FastAPI 路由、请求和响应模型
  - 实现最基础的依赖注入、配置文件加载
- **测试与 CI**：
  - 配置 `pytest` 和 GitHub Actions 进行持续集成
  - 编写一些基本的单元测试确保基础功能正常

**交付标准**：

- FastAPI 服务能够启动并返回 `/health` 端点的 OK 响应
- `docker-compose up` 能成功启动 Qdrant
- 完成基础文件结构搭建，并上传到 GitHub

------

### **Week 2：实现基本的检索与索引功能**

**任务目标**：实现代码库的索引功能，能够读取文件并插入 Qdrant 中。

- **Repo 数据加载**：
  - 创建 `repo_loader.py` 模块，能够从本地路径加载文件（支持 `.py`, `.md`, `.txt` 等文件格式）
  - 实现文件的分块（chunking），按行或段落分割文档内容
  - 利用 `sentence-transformers` 将文档转换为向量嵌入（Embedding）
- **Qdrant 索引与查询**：
  - 使用 Qdrant 存储和查询文档向量
  - 编写 `qdrant_store.py` 用于插入文档向量到 Qdrant，并提供基本的检索接口
- **测试检索功能**：
  - 实现检索接口，能够通过用户输入的问题从 Qdrant 中找到相关文档片段
  - 为文档建立索引并测试查询结果，确保检索正常

**交付标准**：

- 成功将代码库的文档索引到 Qdrant
- `/chat` 接口能够根据用户问题返回相关的文档片段（top-k）

------

### **Week 3：构建 RAG 问答系统（检索 + 拼接 Prompt）**

**任务目标**：实现从 Qdrant 中获取 top-k 结果，并根据检索结果生成回答。

- **检索 + Prompt 拼接**：
  - 从 Qdrant 获取 top-k 文档片段
  - 创建 `prompt.py`，将检索到的片段与用户问题一起拼接，生成输入到 LLM 的 prompt
  - 调用 `llama.cpp` 的 OpenAI 兼容接口进行推理，返回生成的回答
- **回答格式化**：
  - 生成的回答要附带来源信息（包括文件路径和片段）
  - 确保回答中有明确的引用（如 `[SOURCE 1]`）

**交付标准**：

- `/chat` 接口返回检索到的文档片段，并生成带有引用的回答
- 成功展示至少 3 个不同问题的问答，能够看到返回的 `citation` 和相关的文本

------

### **Week 4：添加评测功能（基准评测与回归测试）**

**任务目标**：构建评测框架，能够评估系统的检索与生成效果。

- **自建评测集**：
  - 创建 `coderag_eval_v1.json` 评测数据集，包含问题、黄金答案和必引用的文档路径
  - 编写评测脚本，执行基准评测
- **评测功能**：
  - 在 `/chat` 请求中加入对检索、引用率、生成正确性等指标的评测
  - 提供评测报告，输出 `hit_rate@k`、`citation_rate`、`contains_rate` 等指标
- **回归评测**：
  - 编写回归测试框架，自动记录评测结果并跟踪系统变化

**交付标准**：

- 提供完整的评测报告（例如：`hit_rate@k`、`citation_rate`）
- 能够通过评测集自动进行问答并生成评测结果

------

### **Week 5：优化检索与文档处理（rerank + chunking 优化）**

**任务目标**：优化检索效果，确保文档分块和检索策略最优。

- **文档分块优化**：
  - 优化 chunking 策略，按函数/类分块，而不是简单的按段落/行分块
  - 调整 `chunk_size` 和 `chunk_overlap`，使得每个块能更好地涵盖语义信息
- **检索增强**：
  - 实现基于 BM25 的检索重排（rerank），结合向量检索的结果进行重排序
  - 使得检索结果更符合语义相关度
- **检索性能优化**：
  - 配置 Qdrant 的向量搜索参数，确保查询性能和准确性达到最佳
  - 优化检索速度和响应时间

**交付标准**：

- 检索结果质量有所提升，能够展示 `hit_rate@k` 改进情况
- 文档分块后的检索命中率比基线提升

------

### **Week 6：集成 LoRA 微调与训练（微调与评测对比）**

**任务目标**：实现 LoRA 微调，并与原始模型进行对比评测。

- **LoRA 微调**：
  - 使用 LoRA 或 QLoRA 对模型进行微调，主要微调模型的部分参数（例如，生成部分）
  - 准备微调数据集，确保能进行有效训练
  - 配置训练脚本，监控训练过程
- **性能评估**：
  - 将微调后的模型与原始模型进行对比，使用相同的评测集，输出对比结果（例如：生成质量、幻觉率等）

**交付标准**：

- 提供 `base vs fine-tuned` 的对比结果，能够在评测集上看到明确的改善
- 微调能够有效提高回答的质量，减少幻觉

------

### **Week 7：前端展示与用户交互（Streamlit 或 React）**

**任务目标**：为问答系统构建简单的前端界面，提升用户体验。

- **前端搭建**：
  - 使用 Streamlit 或 React 实现简单的问答界面
  - 前端展示：左侧输入框，右侧显示检索到的文档和生成的回答
- **交互优化**：
  - 实现反馈机制，用户可以标记回答是否有用（有用/没用）
  - 显示 top-k 检索结果、生成的回答和文档路径

**交付标准**：

- 展示前端界面，用户可以通过输入框进行问答
- 展示检索结果和答案，同时支持反馈

------

### **Week 8：优化 API 接口与部署（Docker 一键部署）**

**任务目标**：让项目更具可维护性，方便部署与扩展。

- **API 优化**：
  - 增加更多的功能接口（如文档管理、模型管理、评测结果查看）
  - 优化错误处理、日志记录和监控
- **Docker 部署**：
  - 完善 Docker 配置，确保 API 服务、Qdrant、llama.cpp 能一键启动
  - 解决可能出现的性能瓶颈，优化容器配置

**交付标准**：

- 使用 Docker Compose 实现一键启动，包括 Qdrant 和 FastAPI 服务
- 确保 API 服务与 Qdrant、llama.cpp 完美协作

------

### **Week 9：性能优化与系统稳定性（压测与调优）**

**任务目标**：对系统进行性能优化，提升响应速度与稳定性。

- **压测**：
  - 使用工具（如 Apache Bench 或 locust）进行系统压力测试
  - 分析性能瓶颈，优化代码和系统配置
- **性能调优**：
  - 优化数据库索引、缓存策略
  - 调整查询参数、网络配置，降低延迟

**交付标准**：

- 完成压测，提供性能报告（如：平均响应时间、吞吐量）
- 能在大流量下稳定运行

------

### **Week 10：安全性与防护机制（输入校验与异常处理）**

**任务目标**：加强系统的安全性，防止恶意攻击。

- **输入校验**：
  - 对用户输入进行严格的校验，避免注入攻击
  - 加强 LLM 的输入输出校验，防止不安全的输出
- **异常处理**：
  - 增强错误捕获和日志记录，确保系统出现问题时能够快速定位

**交付标准**：

- 防止常见的输入攻击（如 SQL 注入、XSS）
- 异常处理机制完善，能够清晰地记录和跟踪问题

------

### **Week 11：简历与开源化（展示项目并准备求职）**

**任务目标**：为求职做好准备，开源化项目并优化简历。

- **简历优化**：
  - 更新简历，突出你在项目中负责的技术模块、取得的成效
  - 准备面试时的项目讲解稿（5分钟/15分钟）
- **开源化**：
  - 将项目发布到 GitHub，确保代码清晰、文档完备
  - 提交 1 个 PR 或 issue，增加项目的开源感

**交付标准**：

- 提交项目到 GitHub，并写好 README 文件
- 提供简历和项目演示，准备面试

------

### **Week 12：面试准备与投递**

**任务目标**：加速投递并准备面试。

- **面试模拟**：
  - 进行模拟面试，重点讲解项目的技术细节、工程化流程、微调与评测等内容
- **投递**：
  - 投递 30+ 个相关的实习岗位，进行内推或联系 HR

**交付标准**：

- 完成 30 次投递，并确保能够进行技术面试
- 提供项目面试讲解视频（3-5 分钟）

------

这份计划目标明确，任务层层递进，旨在帮助你三个月内完成一个完整、可用的 LLM/RAG 项目，具备找实习的能力。