# ===========================================
# CodeRAG Lab 环境变量配置
# ===========================================
# 使用说明:
# 1. 复制此文件为 .env.local (本地开发) 或 .env (生产环境)
# 2. 修改配置值
# 3. 重启服务生效
# 
# 配置文件优先级：.env.local > .env > .env.example
# ===========================================

# ===========================================
# 基础服务配置
# ===========================================
PROJECT_NAME=CodeRAG Lab
ENVIRONMENT=development
DEBUG=True
API_HOST=0.0.0.0
API_PORT=8000

# ===========================================
# 向量存储配置 (二选一)
# ===========================================

# 选项 1: Qdrant (推荐)
VECTOR_STORE=qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=coderag

# 选项 2: PostgreSQL + pgvector
# VECTOR_STORE=pgvector
# PGVECTOR_ENABLED=true
# PGVECTOR_CONNECTION_STRING=postgresql://user:password@localhost:5432/dbname

# ===========================================
# Embedding 模型配置
# ===========================================

# 本地模型 (推荐用于开发)
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5
EMBEDDING_DIM=384
EMBEDDING_DEVICE=cpu

# API 模型 (可选)
# EMBEDDING_MODEL=zhipu
# EMBEDDING_MODEL=openai
# ZHIPUAI_API_KEY=your_api_key
# OPENAI_API_KEY=your_api_key

# ===========================================
# LLM 配置 (三选一)
# ===========================================

# 选项 1: MiniMax API (推荐)
LLM_PROVIDER=minimax
MINIMAX_API_KEY=your_minimax_api_key_here
MINIMAX_BASE_URL=https://api.minimax.chat/v1
MINIMAX_MODEL=MiniMax-M2.5

# 选项 2: llama.cpp 本地推理
# LLM_PROVIDER=llamacpp
# LLAMACPP_HOST=localhost
# LLAMACPP_PORT=8080
# LLAMACPP_MODEL_PATH=/path/to/model.gguf

# 选项 3: Ollama 本地推理
# LLM_PROVIDER=ollama
# OLLAMA_HOST=localhost
# OLLAMA_PORT=11434
# OLLAMA_MODEL=llama2

# ===========================================
# 检索增强配置
# ===========================================
ENABLE_FULLTEXT=false
ENABLE_LLM_RERANK=false

# 混合检索权重 (VECTOR + FULLTEXT = 1.0)
VECTOR_WEIGHT=0.7
FULLTEXT_WEIGHT=0.3

# 检索参数
TOP_K=5
MIN_SIMILARITY=0.5

# ===========================================
# 文档分块配置
# ===========================================
CHUNK_SIZE=2000
CHUNK_OVERLAP=200

# ===========================================
# 日志配置
# ===========================================
LOG_LEVEL=INFO
LOG_FILE=logs/coderag.log

# ===========================================
# 数据目录
# ===========================================
DATA_DIR=data

# ===========================================
# 前端配置 (Vue3)
# ===========================================
VITE_API_BASE=/api
VITE_PORT=5173
